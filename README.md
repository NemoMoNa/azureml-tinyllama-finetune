# ðŸ§  Azure ML TinyLlama Fine-Tuning Project

This is a hands-on mini project demonstrating how to run a TinyLlama 1.1B fine-tuning job on Azure Machine Learning from a Mac mini (M4 Pro).

## âœ… Highlights

- âœ… Built a real Azure ML pipeline from scratch
- âœ… Used CLI tools (`az`, `az ml`)
- âœ… Created and used `environment.yml` and `train_job.yml`
- âœ… Deployed a GPU training job using `Standard_NC4as_T4_v3`
- âœ… Learned job tracking, environment management, and workspace setup
- âœ… Controlled cost by avoiding unnecessary GPU inference
- âœ… Saved model output for local testing

## ðŸ’» Files

- `Train_TinyLlama-1.1B-Chat-v1.0.py` â€” LoRA fine-tuning script
- `environment.yml` â€” Conda environment for Azure ML
- `train_job.yml` â€” Azure ML job definition

## ðŸ§­ Usage (CLI)

To run this project on Azure ML:

```bash
az ml job create \
  --file train_job.yml \
  --resource-group <your-resource-group> \
  --workspace-name <your-workspace-name>

## ðŸ“· Screenshots 

### âœ… Job Status Dashboard  
![Job Status](screenshots/job_status.png)

### âœ… Output + Logs Tab  
![Logs](screenshots/output_logs.png)

### âœ… Successful GPU Cluster Execution  
![GPU Cluster](screenshots/gpu_success.png)
